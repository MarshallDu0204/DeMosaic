{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeMosaic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5XMAf4pbZDw",
        "outputId": "495f6cc8-ded5-45ed-de5e-c4efbcee1d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En38bw-nUxWb"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from keras import Input, Model\n",
        "from keras.layers import UpSampling2D, Reshape\n",
        "from keras.layers.convolutional import Conv2D,Conv2DTranspose\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import generic_utils\n",
        "\n",
        "def resizeImg(path,newDir):\n",
        "    imgList = os.listdir(path)\n",
        "    for imgPath in tqdm(imgList):\n",
        "        tmpPath = path+\"/\"+imgPath\n",
        "        img = cv2.imread(tmpPath)\n",
        "        img = cv2.resize(img,(256,256))\n",
        "        tmpName = imgPath.split('.')\n",
        "        cv2.imwrite(newDir+\"/\"+tmpName[0]+'.jpg',img)\n",
        "\n",
        "def mosaicImg(path,newDir):\n",
        "    imgList = os.listdir(path)\n",
        "    for imgPath in tqdm(imgList):\n",
        "        tmpPath = path+\"/\"+imgPath\n",
        "        img = cv2.imread(tmpPath)\n",
        "        mosaicPic = mosaic(img,85,85,105,105)\n",
        "        cv2.imwrite(newDir+\"/\"+imgPath,mosaicPic)\n",
        "\n",
        "def mosaic(img,x,y,w,h,neighbour = 14):\n",
        "    for i in range(0,h - neighbour, neighbour):\n",
        "        for j in range(0, w - neighbour,neighbour):\n",
        "            box = [j+x,i+y,neighbour,neighbour]\n",
        "            color = img[i+y][j+x].tolist()\n",
        "            cv2.rectangle(img,(box[0],box[1]),(box[0]+neighbour-1,box[1]+neighbour-1),color,-1)\n",
        "    return img\n",
        "\n",
        "def preReadData(dataDir1,dataDir2):\n",
        "    trainingData = []\n",
        "    labelData = []\n",
        "    for path in tqdm(os.listdir(dataDir1)):\n",
        "        img = cv2.imread(dataDir1+\"/\"+path)\n",
        "        trainingData.append(img)\n",
        "    for path in tqdm(os.listdir(dataDir2)):\n",
        "        img = cv2.imread(dataDir2+\"/\"+path)\n",
        "        labelData.append(img)\n",
        "    np.save('trainingData.npy',np.asarray(trainingData))\n",
        "    np.save('labelData.npy',np.asarray(labelData))\n",
        "\n",
        "def processImg(imgData):\n",
        "    res = []\n",
        "    for img in imgData:\n",
        "        img = img / 255 - 0.5\n",
        "        res.append(img)\n",
        "    return np.asarray(res)\n",
        "\n",
        "def loadData(trainingPath,labelPath,batch_size):\n",
        "    trainingData = np.load(trainingPath)\n",
        "    labelData =  np.load(labelPath)\n",
        "    while True:\n",
        "        for i in range(0,len(trainingData),batch_size):\n",
        "            trainingImg = processImg(trainingData[i:i+batch_size])\n",
        "            labelImg = processImg(labelData[i:i+batch_size])\n",
        "            yield(trainingImg,labelImg)\n",
        "   \n",
        "\n",
        "def DeMosaicModel():\n",
        "    encoderInput = Input(shape = (256,256,3,))\n",
        "#------Encoder------------\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same', strides=1)(encoderInput)\n",
        "    x = Conv2D(16, (4, 4), activation='relu', padding='same', strides=2)(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same', strides=1)(x)\n",
        "    x = Conv2D(32, (4, 4), activation='relu', padding='same', strides=2)(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=1)(x)\n",
        "    x = Conv2D(64, (4, 4), activation='relu', padding='same', strides=2)(x)\n",
        "    x = Conv2D(128, (4, 4), activation='relu', padding='same', strides=2)(x)\n",
        "    x = Conv2D(128, (4, 4), activation='relu', padding='same', strides=2)(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', strides=1)(x)\n",
        "    x = Conv2D(256, (4, 4), activation='relu', padding='same', strides=2)(x)\n",
        "\n",
        "#------Decoder------------\n",
        "    x = Conv2DTranspose(256, (3,3), activation='relu', padding = 'same',strides = 2)(x)\n",
        "    x = Conv2DTranspose(128, (3,3), activation='relu', padding = 'same',strides = 1)(x)\n",
        "    x = Conv2DTranspose(128, (2,2), activation='relu', padding = 'same',strides = 2)(x)\n",
        "    x = Conv2DTranspose(64, (2,2), activation='relu', padding = 'same',strides = 2)(x)\n",
        "    x = Conv2DTranspose(64, (2,2), activation='relu', padding = 'same',strides = 2)(x)\n",
        "    x = Conv2DTranspose(32, (1,1), activation='relu', padding = 'same',strides = 1)(x)\n",
        "    x = Conv2DTranspose(32, (2,2), activation='relu', padding = 'same',strides = 2)(x)\n",
        "    x = Conv2DTranspose(16, (1,1), activation='relu', padding = 'same',strides = 1)(x)\n",
        "    x = Conv2DTranspose(16, (2,2), activation='relu', padding = 'same',strides = 2)(x)\n",
        "    encoderOutput = Conv2DTranspose(3, (1,1), activation='tanh', padding = 'same',strides = 1)(x)\n",
        "\n",
        "    model = Model(inputs = encoderInput,outputs = encoderOutput)\n",
        "    model_optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "    model.compile(optimizer=model_optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train(modelPath = '/content/drive/My Drive/Colab Notebooks/model/Demosaic.hdf5',batch_size = 50):\n",
        "    model = DeMosaicModel()\n",
        "    if os.path.exists(modelPath):\n",
        "        model.load_weights(modelPath)\n",
        "        print(\"Check point loaded!\")\n",
        "    trainingPath = \"/content/drive/My Drive/Colab Notebooks/trainingData.npy\"\n",
        "    labelPath = \"/content/drive/My Drive/Colab Notebooks/labelData.npy\"\n",
        "    dataGen = loadData(trainingPath,labelPath,batch_size)\n",
        "    r_epochs = 0\n",
        "    num_epochs = 200\n",
        "    epoch_length = 228\n",
        "    bestLoss = np.Inf\n",
        "    iter_num = 0\n",
        "    losses = np.zeros((epoch_length, 2))\n",
        "    for epoch_num in range(num_epochs):\n",
        "        progbar = generic_utils.Progbar(epoch_length)\n",
        "        print('Epoch {}/{}'.format(r_epochs + 1, num_epochs))\n",
        "        r_epochs += 1\n",
        "        while True:\n",
        "            X,Y = next(dataGen)\n",
        "            modelLoss = model.train_on_batch(X,Y)\n",
        "            losses[iter_num, 0] = modelLoss[0]\n",
        "            losses[iter_num, 1] = modelLoss[1]\n",
        "            \n",
        "            iter_num += 1\n",
        "            progbar.update(iter_num, [('loss', np.mean(losses[:iter_num, 0])), ('acc', np.mean(losses[:iter_num, 1]))])\n",
        "            if iter_num == epoch_length:\n",
        "                if modelLoss[0] < bestLoss:\n",
        "                    model.save_weights(modelPath)\n",
        "                iter_num = 0\n",
        "                break\n",
        "\n",
        "def predict(modelPath = '/content/drive/My Drive/Colab Notebooks/model/Demosaic.hdf5',testDataPath = '/content/drive/My Drive/Colab Notebooks/test',OutputPath = '/content/drive/My Drive/Colab Notebooks/output'):\n",
        "    model = DeMosaicModel()\n",
        "    if os.path.exists(modelPath):\n",
        "        model.load_weights(modelPath)\n",
        "        print(\"Model loaded!\")\n",
        "        testData = []\n",
        "        for path in tqdm(os.listdir(testDataPath)):\n",
        "            testImg = testDataPath+\"/\"+path\n",
        "            testImg = cv2.imread(testImg)\n",
        "            testImg = testImg / 255 - 0.5\n",
        "            testData.append(testImg)\n",
        "        testData = np.asarray(testData)\n",
        "        resultImg = model.predict([testData])\n",
        "        i = 0 \n",
        "        for img in resultImg:\n",
        "            i+=1\n",
        "            img = 255 * (img + 0.5)\n",
        "            cv2.imwrite(OutputPath+\"/\"+str(i)+\".jpg\",img)\n",
        "    else:\n",
        "        return\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcLq_7NdLPd6"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXV8B-aGJog0"
      },
      "source": [
        "predict()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}